{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Sequence to Sequence Model - Word Classification\n",
    "Training sequence to sequnce model for recognition of words.\n",
    "## TODO\n",
    "```\n",
    "REMOVE embeddings\n",
    "Overlaping sliders\n",
    "One-shot preprocessing\n",
    "Train preprocessing with RNN\n",
    "lower extra steps, bigger hState, preprocessing?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nilay\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.seq2seq as seq2seq\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "import time\n",
    "import math\n",
    "import unidecode\n",
    "\n",
    "sys.path.append('src')\n",
    "from ocr.datahelpers import load_words_data, corresponding_shuffle, char2idx\n",
    "from ocr.helpers import img_extend\n",
    "from ocr.mlhelpers import TrainingPlot\n",
    "from ocr.tfhelpers import create_cell\n",
    "from ocr.imgtransform import coordinates_remap\n",
    "\n",
    "%matplotlib notebook\n",
    "plt.rcParams['figure.figsize'] = (9.0, 5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading words...\n",
      " |████████████████████████████████████████| 100.0% \n",
      "-> Number of words: 5069\n"
     ]
    }
   ],
   "source": [
    "images, labels = load_words_data(\n",
    "    ['data/processed/breta/words_gaplines/'], load_gaplines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_size = 82 if LANG =='cz' else 52\n",
    "\n",
    "PAD = 0   # Padding\n",
    "EOS = 1   # End of seq\n",
    "\n",
    "num_new_images = 2                 #  Number of new images per image\n",
    "fac_alpha = 2.0                    # Factors for image preprocessing\n",
    "fac_sigma = 0.08\n",
    "\n",
    "num_buckets = 5\n",
    "slider_size = (60, 2)\n",
    "N_INPUT = 60*2                     # Size of sequence input vector\n",
    "vocab_size = char_size + 2         # Number of different chars + <PAD> and <EOS>\n",
    "input_embedding_size = vocab_size  # Size of vector for embedding chars2vec\n",
    "\n",
    "\n",
    "encoder_layers = 2\n",
    "decoder_layers = 2*encoder_layers  # 2* is due to the bidirectional encoder\n",
    "encoder_residual_layers = 1        # HAVE TO be smaller than encoder_layers\n",
    "decoder_residual_layers = 2*encoder_residual_layers\n",
    "encoder_units = 256\n",
    "decoder_units = encoder_units\n",
    "\n",
    "add_output_length = 4 # 4\n",
    "\n",
    "learning_rate = 1e-4               # 1e-4\n",
    "max_gradient_norm = 5.0            # For gradient clipping\n",
    "dropout = 0.4\n",
    "train_per = 0.8                    # Percentage of training data\n",
    "\n",
    "TRAIN_STEPS = 100000               # Number of training steps!\n",
    "TEST_ITER = 150\n",
    "LOSS_ITER = 50\n",
    "SAVE_ITER = 2000\n",
    "BATCH_SIZE = 64\n",
    "EPOCH = 2000                       # Number of batches in epoch - not accurate\n",
    "\n",
    "save_location = 'models/word-clas/' + LANG + '/WordClassifier2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images: 4055\n",
      "Testing images: 1014\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data for later splitting\n",
    "images, labels = corresponding_shuffle([images, labels])\n",
    "\n",
    "labels_idx = np.empty(len(labels), dtype=object)\n",
    "for i, label in enumerate(labels):\n",
    "    labels_idx[i] = [char2idx(c, True) for c in label]\n",
    "    \n",
    "# Split data on train and test dataset\n",
    "div = int(train_per * len(images))\n",
    "\n",
    "trainImages = images[0:div]\n",
    "testImages = images[div:]\n",
    "\n",
    "trainLabels_idx = labels_idx[0:div]\n",
    "testLabels_idx = labels_idx[div:]\n",
    "\n",
    "print(\"Training images:\", div)\n",
    "print(\"Testing images:\", len(images) - div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset extending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed train images 12165\n"
     ]
    }
   ],
   "source": [
    "# Dont mix train and test images\n",
    "trainImagesFinal = np.empty(len(trainImages) * (num_new_images+1), dtype=object)\n",
    "trainLabelsFinal_idx = np.empty(len(trainImages)*(num_new_images+1), dtype=object)\n",
    "for idx, img in enumerate(trainImages):\n",
    "    trainImagesFinal[idx*(num_new_images+1)] = img\n",
    "    trainLabelsFinal_idx[idx*(num_new_images+1)] = trainLabels_idx[idx]\n",
    "    for i in range(num_new_images):\n",
    "        trainImagesFinal[idx*(num_new_images+1) + (i+1)] = coordinates_remap(img, fac_alpha, fac_sigma)\n",
    "        trainLabelsFinal_idx[idx*(num_new_images+1) + (i+1)] = trainLabels_idx[idx]\n",
    "        \n",
    "print(\"Transformed train images\", len(trainImagesFinal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BucketDataIterator():\n",
    "    \"\"\" Iterator for feeding seq2seq model during training \"\"\"\n",
    "    def __init__(self,\n",
    "                 images,\n",
    "                 targets,\n",
    "                 num_buckets=5,\n",
    "                 slider=(60, 30),\n",
    "                 train=True):\n",
    "        \n",
    "        self.train = train\n",
    "        \n",
    "        # First PADDING of images to slider size ( -(a // b) ==  ceil(a/b))\n",
    "        self.slider = slider\n",
    "        for i in range(len(images)):\n",
    "            images[i] = img_extend(\n",
    "                images[i],\n",
    "                (images[i].shape[0], -(-images[i].shape[1] // slider[1]) * slider[1]))\n",
    "        in_length = [image.shape[1]//slider[1] for image in images]\n",
    "        \n",
    "        # Split images to sequence of vectors\n",
    "        imgseq = np.empty(len(images), dtype=object)\n",
    "        for i, img in enumerate(images):\n",
    "            imgseq[i] = [img[:, loc * slider[1]: (loc+1) * slider[1]].flatten()\n",
    "                         for loc in range(in_length[i])]\n",
    "\n",
    "        # Create pandas dataFrame and sort it by images width (length) \n",
    "        self.dataFrame = pd.DataFrame({'in_length': in_length,\n",
    "                                       'out_length': [len(t) for t in targets],\n",
    "                                       'images': imgseq,\n",
    "                                       'targets': targets\n",
    "                                      }).sort_values('in_length').reset_index(drop=True)\n",
    "\n",
    "        bsize = int(len(images) / num_buckets)\n",
    "        self.num_buckets = num_buckets\n",
    "        \n",
    "        # Create buckets by slicing parts by indexes\n",
    "        self.buckets = []\n",
    "        for bucket in range(num_buckets-1):\n",
    "            self.buckets.append(self.dataFrame.iloc[bucket * bsize: (bucket+1) * bsize])\n",
    "        self.buckets.append(self.dataFrame.iloc[(num_buckets-1) * bsize:])        \n",
    "        \n",
    "        self.buckets_size = [len(bucket) for bucket in self.buckets]\n",
    "\n",
    "        # cursor[i] will be the cursor for the ith bucket\n",
    "        self.cursor = np.array([0] * num_buckets)\n",
    "        self.bucket_order = np.random.permutation(num_buckets)\n",
    "        self.bucket_cursor = 0\n",
    "        self.shuffle()\n",
    "        print(\"Iterator created.\")\n",
    "\n",
    "    def shuffle(self, idx=None):\n",
    "        \"\"\" Shuffle idx bucket or each bucket separately \"\"\"\n",
    "        for i in [idx] if idx is not None else range(self.num_buckets):\n",
    "            self.buckets[i] = self.buckets[i].sample(frac=1).reset_index(drop=True)\n",
    "            self.cursor[i] = 0\n",
    "\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"\n",
    "        Creates next training batch of size: batch_size\n",
    "        Retruns: image seq, letter seq,\n",
    "                 image seq lengths, letter seq lengths\n",
    "        \"\"\"\n",
    "        i_bucket = self.bucket_order[self.bucket_cursor]\n",
    "        # Increment cursor and shuffle in case of new round\n",
    "        self.bucket_cursor = (self.bucket_cursor + 1) % self.num_buckets\n",
    "        if self.bucket_cursor == 0:\n",
    "            self.bucket_order = np.random.permutation(self.num_buckets)\n",
    "            \n",
    "        if self.cursor[i_bucket] + batch_size > self.buckets_size[i_bucket]:\n",
    "            self.shuffle(i_bucket)\n",
    "\n",
    "        # Handle too big batch sizes\n",
    "        if (batch_size > self.buckets_size[i_bucket]):\n",
    "            batch_size = self.buckets_size[i_bucket]\n",
    "\n",
    "        res = self.buckets[i_bucket].iloc[self.cursor[i_bucket]:\n",
    "                                          self.cursor[i_bucket]+batch_size]\n",
    "        self.cursor[i_bucket] += batch_size\n",
    "\n",
    "        # PAD input sequence and output\n",
    "        # Pad sequences with <PAD> to same length\n",
    "        input_max = max(res['in_length'])\n",
    "        output_max = max(res['out_length'])\n",
    "        # In order to make it work at production\n",
    "        assert np.all(res['in_length'] + add_output_length >= res['out_length'])\n",
    "        \n",
    "        input_seq = np.zeros((batch_size, input_max, N_INPUT), dtype=np.float32)\n",
    "        for i, img in enumerate(res['images']):\n",
    "            input_seq[i][:res['in_length'].values[i]] = img\n",
    "        input_seq = input_seq.swapaxes(0, 1)\n",
    "        \n",
    "        # Need to pad according to the maximum length output sequence\n",
    "        targets = np.zeros([batch_size, output_max], dtype=np.int32)\n",
    "        for i, target in enumerate(targets):\n",
    "            target[:res['out_length'].values[i]] = res['targets'].values[i]\n",
    "        targets = targets.swapaxes(0, 1)\n",
    "        \n",
    "        return input_seq, targets, res['in_length'].values, res['out_length'].values\n",
    "    \n",
    "    def next_feed(self, size):\n",
    "        \"\"\" Create feed directly for model training \"\"\"\n",
    "        (encoder_inputs_,\n",
    "         decoder_targets_,\n",
    "         encoder_inputs_length_,\n",
    "         decoder_targets_length_) = self.next_batch(size)\n",
    "        return {\n",
    "            encoder_inputs: encoder_inputs_,\n",
    "            encoder_inputs_length: encoder_inputs_length_,\n",
    "            decoder_targets: decoder_targets_,\n",
    "            decoder_targets_length: decoder_targets_length_,\n",
    "            keep_prob: (1.0 - dropout) if self.train else 1.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterator created.\n",
      "Iterator created.\n"
     ]
    }
   ],
   "source": [
    "# Create iterator for feeding RNN\n",
    "# Create only once, it modifies: labels_idx\n",
    "train_iterator = BucketDataIterator(trainImagesFinal,\n",
    "                                    trainLabelsFinal_idx,\n",
    "                                    num_buckets,\n",
    "                                    slider_size,\n",
    "                                    train=True)\n",
    "test_iterator = BucketDataIterator(testImages,\n",
    "                                   testLabels_idx,\n",
    "                                   num_buckets,\n",
    "                                   slider_size,\n",
    "                                   train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input placehodlers\n",
    "# N_INPUT -> size of vector representing one image in sequence\n",
    "# Encoder inputs shape (max_seq_length, batch_size, vec_size)\n",
    "encoder_inputs = tf.placeholder(shape=(None, None, N_INPUT),\n",
    "                                dtype=tf.float32,\n",
    "                                name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,),\n",
    "                                       dtype=tf.int32,\n",
    "                                       name='encoder_inputs_length')\n",
    "# required for training, not required for testing and application\n",
    "decoder_targets = tf.placeholder(shape=(None, None),\n",
    "                                 dtype=tf.int32,\n",
    "                                 name='decoder_targets')\n",
    "decoder_targets_length = tf.placeholder(shape=(None,),\n",
    "                                        dtype=tf.int32,\n",
    "                                        name='decoder_targets_length')\n",
    "# Dropout value\n",
    "keep_prob = tf.placeholder(tf.float32, name='keep_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Train Feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_size, batch_size = tf.unstack(tf.shape(decoder_targets))\n",
    "\n",
    "test_length = tf.floor_div(tf.reduce_max(encoder_inputs_length), 7) + add_output_length\n",
    "\n",
    "EOS_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * EOS\n",
    "PAD_SLICE = tf.ones([1, batch_size], dtype=tf.int32) * PAD\n",
    "\n",
    "# Train inputs with EOS symbol at start of seq\n",
    "decoder_train_inputs = tf.concat([EOS_SLICE, decoder_targets], axis=0)\n",
    "decoder_train_length = decoder_targets_length + 1\n",
    "\n",
    "# train targets with EOS symbol at end of seq\n",
    "decoder_train_targets = tf.concat([decoder_targets, PAD_SLICE], axis=0)\n",
    "decoder_train_targets_seq_len, _ = tf.unstack(tf.shape(decoder_train_targets))\n",
    "decoder_train_targets_eos_mask = tf.one_hot(decoder_train_length - 1,\n",
    "                                            decoder_train_targets_seq_len,\n",
    "                                            on_value=EOS, off_value=PAD,\n",
    "                                            dtype=tf.int32)\n",
    "decoder_train_targets_eos_mask = tf.transpose(decoder_train_targets_eos_mask, [1, 0])\n",
    "\n",
    "# hacky way using one_hot to put EOS symbol at the end of target sequence\n",
    "decoder_train_targets = tf.add(decoder_train_targets,\n",
    "                               decoder_train_targets_eos_mask)\n",
    "\n",
    "# Pad test accuracy\n",
    "decoder_test_targets = tf.pad(\n",
    "    decoder_train_targets,\n",
    "    [[0, test_length - decoder_train_targets_seq_len], [0, 0]],\n",
    "    mode='CONSTANT')\n",
    "\n",
    "loss_weights = tf.sequence_mask(\n",
    "    decoder_train_length,\n",
    "    tf.reduce_max(decoder_train_length),\n",
    "    dtype=tf.float32)\n",
    "\n",
    "test_weights = tf.sequence_mask(\n",
    "    decoder_train_length,\n",
    "    test_length,\n",
    "    dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly initialized embedding matrix, for characters embedding in decoder\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size,\n",
    "                                            input_embedding_size],\n",
    "                                           -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "decoder_train_inputs_embedded = tf.nn.embedding_lookup(\n",
    "    embeddings, decoder_train_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_cell_fw = create_cell(encoder_units,\n",
    "                          encoder_layers,\n",
    "                          encoder_residual_layers,\n",
    "                          is_dropout=True,\n",
    "                          keep_prob=keep_prob)\n",
    "enc_cell_bw = create_cell(encoder_units,\n",
    "                          encoder_layers,\n",
    "                          encoder_residual_layers,\n",
    "                          is_dropout=True,\n",
    "                          keep_prob=keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Help functions for standard layers\n",
    "def conv2d(x, W, name=None):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "def max_pool_2x2(x, name=None):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "# 1. Layer - Convulation variables\n",
    "W_conv1 = tf.get_variable('W_conv1', shape=[5, 5, 1, 4],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[4]), name='b_conv1')\n",
    "# 3. Layer - Convulation variables\n",
    "W_conv2 = tf.get_variable('W_conv2', shape=[5, 5, 4, 8],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[8]), name='b_conv2')\n",
    "\n",
    "def CNN(x):\n",
    "    x = tf.image.per_image_standardization(x)\n",
    "    x_img = tf.reshape(x, [1, slider_size[0], slider_size[1], 1])\n",
    "    # 1. Layer - Convulation\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_img, W_conv1) + b_conv1, name='h_conv1')\n",
    "    # 2. Layer - Max Pool\n",
    "    h_pool1 = max_pool_2x2(h_conv1, name='h_pool1')\n",
    "    # 3. Layer - Convulation\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2, name='h_conv2')\n",
    "    # 4. Layer - Max Pool\n",
    "    return max_pool_2x2(h_conv2, name='h_pool2')\n",
    "\n",
    "# Input images CNN\n",
    "inputs = tf.map_fn(\n",
    "    lambda seq: tf.map_fn(\n",
    "        lambda img:\n",
    "            tf.reshape(\n",
    "                CNN(tf.reshape(img, [slider_size[0], slider_size[1], 1])), [-1]),\n",
    "        seq),\n",
    "    encoder_inputs,\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# Bidirectional RNN, gibe fw and bw outputs separately\n",
    "enc_outputs, enc_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "    cell_fw = enc_cell_fw,\n",
    "    cell_bw = enc_cell_bw,\n",
    "    inputs = inputs,\n",
    "    sequence_length = encoder_inputs_length,\n",
    "    dtype = tf.float32,\n",
    "    time_major = True)\n",
    "\n",
    "encoder_outputs = tf.concat(enc_outputs, -1)\n",
    "\n",
    "if encoder_layers == 1:\n",
    "    encoder_state = enc_state\n",
    "else:\n",
    "    encoder_state = []\n",
    "    for layer_id in range(encoder_layers):\n",
    "        encoder_state.append(enc_state[0][layer_id])  # forward\n",
    "        encoder_state.append(enc_state[1][layer_id])  # backward\n",
    "    encoder_state = tuple(encoder_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_states: size [batch_size, max_time, num_units]\n",
    "attention_states = tf.transpose(encoder_outputs, [1, 0, 2])\n",
    "\n",
    "# Create an attention mechanism\n",
    "attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "    decoder_units, attention_states,\n",
    "    memory_sequence_length=encoder_inputs_length)\n",
    "\n",
    "\n",
    "decoder_cell = create_cell(decoder_units,\n",
    "                           decoder_layers,\n",
    "                           decoder_residual_layers,\n",
    "                           is_dropout=True,\n",
    "                           keep_prob=keep_prob)\n",
    "\n",
    "decoder_cell = seq2seq.AttentionWrapper(\n",
    "    decoder_cell, attention_mechanism,\n",
    "    attention_layer_size=decoder_units)\n",
    "\n",
    "decoder_initial_state = decoder_cell.zero_state(batch_size, tf.float32).clone(\n",
    "    cell_state=encoder_state)\n",
    "\n",
    "### TRAIN DECODER ###\n",
    "# Helper\n",
    "helper = seq2seq.TrainingHelper(\n",
    "    decoder_train_inputs_embedded, decoder_train_length, time_major=True)\n",
    "\n",
    "# Decoder\n",
    "projection_layer = layers_core.Dense(\n",
    "    vocab_size, use_bias=False)\n",
    "\n",
    "decoder = seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper, decoder_initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "# outputs.rnn_output   = plain output\n",
    "# outputs.sample_id = tf.argmax(outputs.rnn_output, axis=-1)\n",
    "outputs, final_context_state, _ = seq2seq.dynamic_decode(\n",
    "    decoder)\n",
    "\n",
    "logits_train = outputs.rnn_output\n",
    "prediction_train = outputs.sample_id\n",
    "\n",
    "\n",
    "### INFERENCE DECODER ###\n",
    "# Helper\n",
    "helper_infer = seq2seq.GreedyEmbeddingHelper(\n",
    "    embeddings,\n",
    "    tf.fill([batch_size], EOS), EOS)\n",
    "\n",
    "# Decoder\n",
    "decoder_infer = seq2seq.BasicDecoder(\n",
    "    decoder_cell, helper_infer, decoder_initial_state,\n",
    "    output_layer=projection_layer)\n",
    "\n",
    "# Dynamic decoding\n",
    "outputs_infer, final_context_state, final_seq_lengths = seq2seq.dynamic_decode(\n",
    "    decoder_infer,\n",
    "    impute_finished=True,\n",
    "#     maximum_iterations=tf.reduce_max(encoder_inputs_length) + add_output_length)\n",
    "    maximum_iterations=test_length)\n",
    "prediction_inference = tf.identity(outputs_infer.sample_id,\n",
    "                                   name='prediction_infer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = tf.transpose(decoder_train_targets, [1, 0])\n",
    "test_targets = tf.transpose(decoder_test_targets, [1, 0])\n",
    "## Loss\n",
    "loss = seq2seq.sequence_loss(logits=logits_train,\n",
    "                             targets=targets,\n",
    "                             weights=loss_weights,\n",
    "                             name='loss')\n",
    "\n",
    "## Calculate and clip gradients\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "    gradients, max_gradient_norm)\n",
    "\n",
    "### Optimization\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params),\n",
    "    name='train_step')\n",
    "\n",
    "\n",
    "### Evaluate model\n",
    "# Pad prediction to match lengths\n",
    "prediction_infer_padded = tf.pad(\n",
    "    prediction_inference,\n",
    "    [[0, 0], [0, test_length - tf.reduce_max(final_seq_lengths)]],\n",
    "    mode='CONSTANT')\n",
    "\n",
    "correct_prediction = tf.equal(prediction_infer_padded,\n",
    "                              test_targets)\n",
    "## Advanced accuracy only the elements of seq including EOS symbol\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct_prediction, tf.float32)*test_weights)/tf.reduce_sum(test_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0 - loss: 3.9814613\n",
      "    expected  > [43 42 30 36 47 28 30  1  0  0  0  0  0  0  0]\n",
      "    predicted > [42 42 42 42 42 42 42 42 42 42 42  9  9 26 26]\n",
      "    expected  > [ 3 48 40  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [ 9  9  9  9 26 26 26 26 26 26 26 26 16 16 16]\n",
      "\n",
      "batch 2000 - loss: 1.8423418\n",
      "    expected  > [41 32 37 39 32 43 46 36  1  0  0  0  0  0  0]\n",
      "    predicted > [46 32 37 39 32 49 32  1  0  0  0  0  0  0  0]\n",
      "    expected  > [52 32 39 39 42 50  1  0  0  0  0  0  0  0  0]\n",
      "    predicted > [42 39 42 49  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "Training interrupted, model saved.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b61d83f128>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Creat plot for live stats ploting\n",
    "trainPlot = TrainingPlot(TRAIN_STEPS, TEST_ITER, LOSS_ITER)\n",
    "\n",
    "try:\n",
    "    for i_batch in range(TRAIN_STEPS):\n",
    "        fd = train_iterator.next_feed(BATCH_SIZE)\n",
    "        train_step.run(fd)\n",
    "        \n",
    "        if i_batch % LOSS_ITER == 0:\n",
    "            # Plotting loss\n",
    "            tmpLoss = loss.eval(fd)\n",
    "            trainPlot.update_loss(tmpLoss, i_batch // LOSS_ITER)\n",
    "    \n",
    "        if i_batch % TEST_ITER == 0:\n",
    "            # Plotting accuracy\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            accTest = accuracy.eval(fd_test)\n",
    "            accTrain = accuracy.eval(fd)\n",
    "            trainPlot.update_acc(accTest, accTrain, i_batch // TEST_ITER)\n",
    "\n",
    "        if i_batch % SAVE_ITER == 0:\n",
    "            saver.save(sess, save_location)\n",
    "        \n",
    "        if i_batch % EPOCH == 0:\n",
    "            fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "            print('batch %r - loss: %r' % (i_batch, sess.run(loss, fd_test)))\n",
    "            predict_, target_ = sess.run([prediction_infer_padded, test_targets], fd_test)\n",
    "            for i, (inp, pred) in enumerate(zip(target_, predict_)):\n",
    "                print('    expected  > {}'.format(inp))\n",
    "                print('    predicted > {}'.format(pred))\n",
    "                if i >= 1:\n",
    "                    break\n",
    "            print()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    saver.save(sess, save_location)\n",
    "    print('Training interrupted, model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    expected  > [ 7 48 41 41 52  1  0  0  0  0  0]\n",
      "    predicted > [20 42 40 42 45 52  1  0  0  0  0]\n",
      "    expected  > [39 36 38 32 39 52  1  0  0  0  0]\n",
      "    predicted > [47 36 39 52  1  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [50 28 36 47  1  0  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [50 32 41 32 39  1  0  0  0  0  0  0  0  0  0]\n",
      "    expected  > [20 28 31 45 28  1  0  0  0  0  0  0  0  0  0]\n",
      "    predicted > [17 28 38 28  1  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [47 36 53  1  0  0  0  0  0  0  0]\n",
      "    predicted > [47 36 38  1  0  0  0  0  0  0  0]\n",
      "    expected  > [40 39 28 31 52  1  0  0  0  0  0]\n",
      "    predicted > [41 32 38 52  1  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [34 28 53 36 41 34  1  0  0  0  0  0  0]\n",
      "    predicted > [43 45 28 41 32  1  0  0  0  0  0  0  0]\n",
      "    expected  > [35 42 40 32  1  0  0  0  0  0  0  0  0]\n",
      "    predicted > [47 42 41 32  1  0  0  0  0  0  0  0  0]\n",
      "\n",
      "    expected  > [34  1  0  0  0  0  0  0  0]\n",
      "    predicted > [26  1  0  0  0  0  0  0  0]\n",
      "    expected  > [30 28 37 32  1  0  0  0  0]\n",
      "    predicted > [49 52 37  1  0  0  0  0  0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    fd_test = test_iterator.next_feed(BATCH_SIZE)\n",
    "    predict_, target_ = sess.run([prediction_infer_padded, test_targets], fd_test)\n",
    "    for i, (inp, pred) in enumerate(zip(target_, predict_)):\n",
    "        print('    expected  > {}'.format(inp))\n",
    "        print('    predicted > {}'.format(pred))\n",
    "        if i >= 1:\n",
    "            break\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
